{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "62b38361",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: nltk in ./opt/anaconda3/lib/python3.9/site-packages (3.7)\r\n",
      "Requirement already satisfied: regex>=2021.8.3 in ./opt/anaconda3/lib/python3.9/site-packages (from nltk) (2022.3.15)\r\n",
      "Requirement already satisfied: click in ./opt/anaconda3/lib/python3.9/site-packages (from nltk) (8.0.4)\r\n",
      "Requirement already satisfied: tqdm in ./opt/anaconda3/lib/python3.9/site-packages (from nltk) (4.64.0)\r\n",
      "Requirement already satisfied: joblib in ./opt/anaconda3/lib/python3.9/site-packages (from nltk) (1.1.0)\r\n"
     ]
    }
   ],
   "source": [
    "!pip install nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c7b28402",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading collection 'all'\n",
      "[nltk_data]    | \n",
      "[nltk_data]    | Downloading package abc to\n",
      "[nltk_data]    |     /Users/gemmanoguera/nltk_data...\n",
      "[nltk_data]    |   Package abc is already up-to-date!\n",
      "[nltk_data]    | Downloading package alpino to\n",
      "[nltk_data]    |     /Users/gemmanoguera/nltk_data...\n",
      "[nltk_data]    |   Package alpino is already up-to-date!\n",
      "[nltk_data]    | Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]    |     /Users/gemmanoguera/nltk_data...\n",
      "[nltk_data]    |   Package averaged_perceptron_tagger is already up-\n",
      "[nltk_data]    |       to-date!\n",
      "[nltk_data]    | Downloading package averaged_perceptron_tagger_ru to\n",
      "[nltk_data]    |     /Users/gemmanoguera/nltk_data...\n",
      "[nltk_data]    |   Package averaged_perceptron_tagger_ru is already\n",
      "[nltk_data]    |       up-to-date!\n",
      "[nltk_data]    | Downloading package basque_grammars to\n",
      "[nltk_data]    |     /Users/gemmanoguera/nltk_data...\n",
      "[nltk_data]    |   Package basque_grammars is already up-to-date!\n",
      "[nltk_data]    | Downloading package bcp47 to\n",
      "[nltk_data]    |     /Users/gemmanoguera/nltk_data...\n",
      "[nltk_data]    |   Package bcp47 is already up-to-date!\n",
      "[nltk_data]    | Downloading package biocreative_ppi to\n",
      "[nltk_data]    |     /Users/gemmanoguera/nltk_data...\n",
      "[nltk_data]    |   Package biocreative_ppi is already up-to-date!\n",
      "[nltk_data]    | Downloading package bllip_wsj_no_aux to\n",
      "[nltk_data]    |     /Users/gemmanoguera/nltk_data...\n",
      "[nltk_data]    |   Package bllip_wsj_no_aux is already up-to-date!\n",
      "[nltk_data]    | Downloading package book_grammars to\n",
      "[nltk_data]    |     /Users/gemmanoguera/nltk_data...\n",
      "[nltk_data]    |   Package book_grammars is already up-to-date!\n",
      "[nltk_data]    | Downloading package brown to\n",
      "[nltk_data]    |     /Users/gemmanoguera/nltk_data...\n",
      "[nltk_data]    |   Package brown is already up-to-date!\n",
      "[nltk_data]    | Downloading package brown_tei to\n",
      "[nltk_data]    |     /Users/gemmanoguera/nltk_data...\n",
      "[nltk_data]    |   Package brown_tei is already up-to-date!\n",
      "[nltk_data]    | Downloading package cess_cat to\n",
      "[nltk_data]    |     /Users/gemmanoguera/nltk_data...\n",
      "[nltk_data]    |   Package cess_cat is already up-to-date!\n",
      "[nltk_data]    | Downloading package cess_esp to\n",
      "[nltk_data]    |     /Users/gemmanoguera/nltk_data...\n",
      "[nltk_data]    |   Package cess_esp is already up-to-date!\n",
      "[nltk_data]    | Downloading package chat80 to\n",
      "[nltk_data]    |     /Users/gemmanoguera/nltk_data...\n",
      "[nltk_data]    |   Package chat80 is already up-to-date!\n",
      "[nltk_data]    | Downloading package city_database to\n",
      "[nltk_data]    |     /Users/gemmanoguera/nltk_data...\n",
      "[nltk_data]    |   Package city_database is already up-to-date!\n",
      "[nltk_data]    | Downloading package cmudict to\n",
      "[nltk_data]    |     /Users/gemmanoguera/nltk_data...\n",
      "[nltk_data]    |   Package cmudict is already up-to-date!\n",
      "[nltk_data]    | Downloading package comparative_sentences to\n",
      "[nltk_data]    |     /Users/gemmanoguera/nltk_data...\n",
      "[nltk_data]    |   Package comparative_sentences is already up-to-\n",
      "[nltk_data]    |       date!\n",
      "[nltk_data]    | Downloading package comtrans to\n",
      "[nltk_data]    |     /Users/gemmanoguera/nltk_data...\n",
      "[nltk_data]    |   Package comtrans is already up-to-date!\n",
      "[nltk_data]    | Downloading package conll2000 to\n",
      "[nltk_data]    |     /Users/gemmanoguera/nltk_data...\n",
      "[nltk_data]    |   Package conll2000 is already up-to-date!\n",
      "[nltk_data]    | Downloading package conll2002 to\n",
      "[nltk_data]    |     /Users/gemmanoguera/nltk_data...\n",
      "[nltk_data]    |   Package conll2002 is already up-to-date!\n",
      "[nltk_data]    | Downloading package conll2007 to\n",
      "[nltk_data]    |     /Users/gemmanoguera/nltk_data...\n",
      "[nltk_data]    |   Package conll2007 is already up-to-date!\n",
      "[nltk_data]    | Downloading package crubadan to\n",
      "[nltk_data]    |     /Users/gemmanoguera/nltk_data...\n",
      "[nltk_data]    |   Package crubadan is already up-to-date!\n",
      "[nltk_data]    | Downloading package dependency_treebank to\n",
      "[nltk_data]    |     /Users/gemmanoguera/nltk_data...\n",
      "[nltk_data]    |   Package dependency_treebank is already up-to-date!\n",
      "[nltk_data]    | Downloading package dolch to\n",
      "[nltk_data]    |     /Users/gemmanoguera/nltk_data...\n",
      "[nltk_data]    |   Package dolch is already up-to-date!\n",
      "[nltk_data]    | Downloading package europarl_raw to\n",
      "[nltk_data]    |     /Users/gemmanoguera/nltk_data...\n",
      "[nltk_data]    |   Package europarl_raw is already up-to-date!\n",
      "[nltk_data]    | Downloading package extended_omw to\n",
      "[nltk_data]    |     /Users/gemmanoguera/nltk_data...\n",
      "[nltk_data]    |   Package extended_omw is already up-to-date!\n",
      "[nltk_data]    | Downloading package floresta to\n",
      "[nltk_data]    |     /Users/gemmanoguera/nltk_data...\n",
      "[nltk_data]    |   Package floresta is already up-to-date!\n",
      "[nltk_data]    | Downloading package framenet_v15 to\n",
      "[nltk_data]    |     /Users/gemmanoguera/nltk_data...\n",
      "[nltk_data]    |   Package framenet_v15 is already up-to-date!\n",
      "[nltk_data]    | Downloading package framenet_v17 to\n",
      "[nltk_data]    |     /Users/gemmanoguera/nltk_data...\n",
      "[nltk_data]    |   Package framenet_v17 is already up-to-date!\n",
      "[nltk_data]    | Downloading package gazetteers to\n",
      "[nltk_data]    |     /Users/gemmanoguera/nltk_data...\n",
      "[nltk_data]    |   Package gazetteers is already up-to-date!\n",
      "[nltk_data]    | Downloading package genesis to\n",
      "[nltk_data]    |     /Users/gemmanoguera/nltk_data...\n",
      "[nltk_data]    |   Package genesis is already up-to-date!\n",
      "[nltk_data]    | Downloading package gutenberg to\n",
      "[nltk_data]    |     /Users/gemmanoguera/nltk_data...\n",
      "[nltk_data]    |   Package gutenberg is already up-to-date!\n",
      "[nltk_data]    | Downloading package ieer to\n",
      "[nltk_data]    |     /Users/gemmanoguera/nltk_data...\n",
      "[nltk_data]    |   Package ieer is already up-to-date!\n",
      "[nltk_data]    | Downloading package inaugural to\n",
      "[nltk_data]    |     /Users/gemmanoguera/nltk_data...\n",
      "[nltk_data]    |   Package inaugural is already up-to-date!\n",
      "[nltk_data]    | Downloading package indian to\n",
      "[nltk_data]    |     /Users/gemmanoguera/nltk_data...\n",
      "[nltk_data]    |   Package indian is already up-to-date!\n",
      "[nltk_data]    | Downloading package jeita to\n",
      "[nltk_data]    |     /Users/gemmanoguera/nltk_data...\n",
      "[nltk_data]    |   Package jeita is already up-to-date!\n",
      "[nltk_data]    | Downloading package kimmo to\n",
      "[nltk_data]    |     /Users/gemmanoguera/nltk_data...\n",
      "[nltk_data]    |   Package kimmo is already up-to-date!\n",
      "[nltk_data]    | Downloading package knbc to\n",
      "[nltk_data]    |     /Users/gemmanoguera/nltk_data...\n",
      "[nltk_data]    |   Package knbc is already up-to-date!\n",
      "[nltk_data]    | Downloading package large_grammars to\n",
      "[nltk_data]    |     /Users/gemmanoguera/nltk_data...\n",
      "[nltk_data]    |   Package large_grammars is already up-to-date!\n",
      "[nltk_data]    | Downloading package lin_thesaurus to\n",
      "[nltk_data]    |     /Users/gemmanoguera/nltk_data...\n",
      "[nltk_data]    |   Package lin_thesaurus is already up-to-date!\n",
      "[nltk_data]    | Downloading package mac_morpho to\n",
      "[nltk_data]    |     /Users/gemmanoguera/nltk_data...\n",
      "[nltk_data]    |   Package mac_morpho is already up-to-date!\n",
      "[nltk_data]    | Downloading package machado to\n",
      "[nltk_data]    |     /Users/gemmanoguera/nltk_data...\n",
      "[nltk_data]    |   Package machado is already up-to-date!\n",
      "[nltk_data]    | Downloading package masc_tagged to\n",
      "[nltk_data]    |     /Users/gemmanoguera/nltk_data...\n",
      "[nltk_data]    |   Package masc_tagged is already up-to-date!\n",
      "[nltk_data]    | Downloading package maxent_ne_chunker to\n",
      "[nltk_data]    |     /Users/gemmanoguera/nltk_data...\n",
      "[nltk_data]    |   Package maxent_ne_chunker is already up-to-date!\n",
      "[nltk_data]    | Downloading package maxent_treebank_pos_tagger to\n",
      "[nltk_data]    |     /Users/gemmanoguera/nltk_data...\n",
      "[nltk_data]    |   Package maxent_treebank_pos_tagger is already up-\n",
      "[nltk_data]    |       to-date!\n",
      "[nltk_data]    | Downloading package moses_sample to\n",
      "[nltk_data]    |     /Users/gemmanoguera/nltk_data...\n",
      "[nltk_data]    |   Package moses_sample is already up-to-date!\n",
      "[nltk_data]    | Downloading package movie_reviews to\n",
      "[nltk_data]    |     /Users/gemmanoguera/nltk_data...\n",
      "[nltk_data]    |   Package movie_reviews is already up-to-date!\n",
      "[nltk_data]    | Downloading package mte_teip5 to\n",
      "[nltk_data]    |     /Users/gemmanoguera/nltk_data...\n",
      "[nltk_data]    |   Package mte_teip5 is already up-to-date!\n",
      "[nltk_data]    | Downloading package mwa_ppdb to\n",
      "[nltk_data]    |     /Users/gemmanoguera/nltk_data...\n",
      "[nltk_data]    |   Package mwa_ppdb is already up-to-date!\n",
      "[nltk_data]    | Downloading package names to\n",
      "[nltk_data]    |     /Users/gemmanoguera/nltk_data...\n",
      "[nltk_data]    |   Package names is already up-to-date!\n",
      "[nltk_data]    | Downloading package nombank.1.0 to\n",
      "[nltk_data]    |     /Users/gemmanoguera/nltk_data...\n",
      "[nltk_data]    |   Package nombank.1.0 is already up-to-date!\n",
      "[nltk_data]    | Downloading package nonbreaking_prefixes to\n",
      "[nltk_data]    |     /Users/gemmanoguera/nltk_data...\n",
      "[nltk_data]    |   Package nonbreaking_prefixes is already up-to-date!\n",
      "[nltk_data]    | Downloading package nps_chat to\n",
      "[nltk_data]    |     /Users/gemmanoguera/nltk_data...\n",
      "[nltk_data]    |   Package nps_chat is already up-to-date!\n",
      "[nltk_data]    | Downloading package omw to\n",
      "[nltk_data]    |     /Users/gemmanoguera/nltk_data...\n",
      "[nltk_data]    |   Package omw is already up-to-date!\n",
      "[nltk_data]    | Downloading package omw-1.4 to\n",
      "[nltk_data]    |     /Users/gemmanoguera/nltk_data...\n",
      "[nltk_data]    |   Package omw-1.4 is already up-to-date!\n",
      "[nltk_data]    | Downloading package opinion_lexicon to\n",
      "[nltk_data]    |     /Users/gemmanoguera/nltk_data...\n",
      "[nltk_data]    |   Package opinion_lexicon is already up-to-date!\n",
      "[nltk_data]    | Downloading package panlex_swadesh to\n",
      "[nltk_data]    |     /Users/gemmanoguera/nltk_data...\n",
      "[nltk_data]    |   Package panlex_swadesh is already up-to-date!\n",
      "[nltk_data]    | Downloading package paradigms to\n",
      "[nltk_data]    |     /Users/gemmanoguera/nltk_data...\n",
      "[nltk_data]    |   Package paradigms is already up-to-date!\n",
      "[nltk_data]    | Downloading package pe08 to\n",
      "[nltk_data]    |     /Users/gemmanoguera/nltk_data...\n",
      "[nltk_data]    |   Package pe08 is already up-to-date!\n",
      "[nltk_data]    | Downloading package perluniprops to\n",
      "[nltk_data]    |     /Users/gemmanoguera/nltk_data...\n",
      "[nltk_data]    |   Package perluniprops is already up-to-date!\n",
      "[nltk_data]    | Downloading package pil to\n",
      "[nltk_data]    |     /Users/gemmanoguera/nltk_data...\n",
      "[nltk_data]    |   Package pil is already up-to-date!\n",
      "[nltk_data]    | Downloading package pl196x to\n",
      "[nltk_data]    |     /Users/gemmanoguera/nltk_data...\n",
      "[nltk_data]    |   Package pl196x is already up-to-date!\n",
      "[nltk_data]    | Downloading package porter_test to\n",
      "[nltk_data]    |     /Users/gemmanoguera/nltk_data...\n",
      "[nltk_data]    |   Package porter_test is already up-to-date!\n",
      "[nltk_data]    | Downloading package ppattach to\n",
      "[nltk_data]    |     /Users/gemmanoguera/nltk_data...\n",
      "[nltk_data]    |   Package ppattach is already up-to-date!\n",
      "[nltk_data]    | Downloading package problem_reports to\n",
      "[nltk_data]    |     /Users/gemmanoguera/nltk_data...\n",
      "[nltk_data]    |   Package problem_reports is already up-to-date!\n",
      "[nltk_data]    | Downloading package product_reviews_1 to\n",
      "[nltk_data]    |     /Users/gemmanoguera/nltk_data...\n",
      "[nltk_data]    |   Package product_reviews_1 is already up-to-date!\n",
      "[nltk_data]    | Downloading package product_reviews_2 to\n",
      "[nltk_data]    |     /Users/gemmanoguera/nltk_data...\n",
      "[nltk_data]    |   Package product_reviews_2 is already up-to-date!\n",
      "[nltk_data]    | Downloading package propbank to\n",
      "[nltk_data]    |     /Users/gemmanoguera/nltk_data...\n",
      "[nltk_data]    |   Package propbank is already up-to-date!\n",
      "[nltk_data]    | Downloading package pros_cons to\n",
      "[nltk_data]    |     /Users/gemmanoguera/nltk_data...\n",
      "[nltk_data]    |   Package pros_cons is already up-to-date!\n",
      "[nltk_data]    | Downloading package ptb to\n",
      "[nltk_data]    |     /Users/gemmanoguera/nltk_data...\n",
      "[nltk_data]    |   Package ptb is already up-to-date!\n",
      "[nltk_data]    | Downloading package punkt to\n",
      "[nltk_data]    |     /Users/gemmanoguera/nltk_data...\n",
      "[nltk_data]    |   Package punkt is already up-to-date!\n",
      "[nltk_data]    | Downloading package qc to\n",
      "[nltk_data]    |     /Users/gemmanoguera/nltk_data...\n",
      "[nltk_data]    |   Package qc is already up-to-date!\n",
      "[nltk_data]    | Downloading package reuters to\n",
      "[nltk_data]    |     /Users/gemmanoguera/nltk_data...\n",
      "[nltk_data]    |   Package reuters is already up-to-date!\n",
      "[nltk_data]    | Downloading package rslp to\n",
      "[nltk_data]    |     /Users/gemmanoguera/nltk_data...\n",
      "[nltk_data]    |   Package rslp is already up-to-date!\n",
      "[nltk_data]    | Downloading package rte to\n",
      "[nltk_data]    |     /Users/gemmanoguera/nltk_data...\n",
      "[nltk_data]    |   Package rte is already up-to-date!\n",
      "[nltk_data]    | Downloading package sample_grammars to\n",
      "[nltk_data]    |     /Users/gemmanoguera/nltk_data...\n",
      "[nltk_data]    |   Package sample_grammars is already up-to-date!\n",
      "[nltk_data]    | Downloading package semcor to\n",
      "[nltk_data]    |     /Users/gemmanoguera/nltk_data...\n",
      "[nltk_data]    |   Package semcor is already up-to-date!\n",
      "[nltk_data]    | Downloading package senseval to\n",
      "[nltk_data]    |     /Users/gemmanoguera/nltk_data...\n",
      "[nltk_data]    |   Package senseval is already up-to-date!\n",
      "[nltk_data]    | Downloading package sentence_polarity to\n",
      "[nltk_data]    |     /Users/gemmanoguera/nltk_data...\n",
      "[nltk_data]    |   Package sentence_polarity is already up-to-date!\n",
      "[nltk_data]    | Downloading package sentiwordnet to\n",
      "[nltk_data]    |     /Users/gemmanoguera/nltk_data...\n",
      "[nltk_data]    |   Package sentiwordnet is already up-to-date!\n",
      "[nltk_data]    | Downloading package shakespeare to\n",
      "[nltk_data]    |     /Users/gemmanoguera/nltk_data...\n",
      "[nltk_data]    |   Package shakespeare is already up-to-date!\n",
      "[nltk_data]    | Downloading package sinica_treebank to\n",
      "[nltk_data]    |     /Users/gemmanoguera/nltk_data...\n",
      "[nltk_data]    |   Package sinica_treebank is already up-to-date!\n",
      "[nltk_data]    | Downloading package smultron to\n",
      "[nltk_data]    |     /Users/gemmanoguera/nltk_data...\n",
      "[nltk_data]    |   Package smultron is already up-to-date!\n",
      "[nltk_data]    | Downloading package snowball_data to\n",
      "[nltk_data]    |     /Users/gemmanoguera/nltk_data...\n",
      "[nltk_data]    |   Package snowball_data is already up-to-date!\n",
      "[nltk_data]    | Downloading package spanish_grammars to\n",
      "[nltk_data]    |     /Users/gemmanoguera/nltk_data...\n",
      "[nltk_data]    |   Package spanish_grammars is already up-to-date!\n",
      "[nltk_data]    | Downloading package state_union to\n",
      "[nltk_data]    |     /Users/gemmanoguera/nltk_data...\n",
      "[nltk_data]    |   Package state_union is already up-to-date!\n",
      "[nltk_data]    | Downloading package stopwords to\n",
      "[nltk_data]    |     /Users/gemmanoguera/nltk_data...\n",
      "[nltk_data]    |   Package stopwords is already up-to-date!\n",
      "[nltk_data]    | Downloading package subjectivity to\n",
      "[nltk_data]    |     /Users/gemmanoguera/nltk_data...\n",
      "[nltk_data]    |   Package subjectivity is already up-to-date!\n",
      "[nltk_data]    | Downloading package swadesh to\n",
      "[nltk_data]    |     /Users/gemmanoguera/nltk_data...\n",
      "[nltk_data]    |   Package swadesh is already up-to-date!\n",
      "[nltk_data]    | Downloading package switchboard to\n",
      "[nltk_data]    |     /Users/gemmanoguera/nltk_data...\n",
      "[nltk_data]    |   Package switchboard is already up-to-date!\n",
      "[nltk_data]    | Downloading package tagsets to\n",
      "[nltk_data]    |     /Users/gemmanoguera/nltk_data...\n",
      "[nltk_data]    |   Package tagsets is already up-to-date!\n",
      "[nltk_data]    | Downloading package timit to\n",
      "[nltk_data]    |     /Users/gemmanoguera/nltk_data...\n",
      "[nltk_data]    |   Package timit is already up-to-date!\n",
      "[nltk_data]    | Downloading package toolbox to\n",
      "[nltk_data]    |     /Users/gemmanoguera/nltk_data...\n",
      "[nltk_data]    |   Package toolbox is already up-to-date!\n",
      "[nltk_data]    | Downloading package treebank to\n",
      "[nltk_data]    |     /Users/gemmanoguera/nltk_data...\n",
      "[nltk_data]    |   Package treebank is already up-to-date!\n",
      "[nltk_data]    | Downloading package twitter_samples to\n",
      "[nltk_data]    |     /Users/gemmanoguera/nltk_data...\n",
      "[nltk_data]    |   Package twitter_samples is already up-to-date!\n",
      "[nltk_data]    | Downloading package udhr to\n",
      "[nltk_data]    |     /Users/gemmanoguera/nltk_data...\n",
      "[nltk_data]    |   Package udhr is already up-to-date!\n",
      "[nltk_data]    | Downloading package udhr2 to\n",
      "[nltk_data]    |     /Users/gemmanoguera/nltk_data...\n",
      "[nltk_data]    |   Package udhr2 is already up-to-date!\n",
      "[nltk_data]    | Downloading package unicode_samples to\n",
      "[nltk_data]    |     /Users/gemmanoguera/nltk_data...\n",
      "[nltk_data]    |   Package unicode_samples is already up-to-date!\n",
      "[nltk_data]    | Downloading package universal_tagset to\n",
      "[nltk_data]    |     /Users/gemmanoguera/nltk_data...\n",
      "[nltk_data]    |   Package universal_tagset is already up-to-date!\n",
      "[nltk_data]    | Downloading package universal_treebanks_v20 to\n",
      "[nltk_data]    |     /Users/gemmanoguera/nltk_data...\n",
      "[nltk_data]    |   Package universal_treebanks_v20 is already up-to-\n",
      "[nltk_data]    |       date!\n",
      "[nltk_data]    | Downloading package vader_lexicon to\n",
      "[nltk_data]    |     /Users/gemmanoguera/nltk_data...\n",
      "[nltk_data]    |   Package vader_lexicon is already up-to-date!\n",
      "[nltk_data]    | Downloading package verbnet to\n",
      "[nltk_data]    |     /Users/gemmanoguera/nltk_data...\n",
      "[nltk_data]    |   Package verbnet is already up-to-date!\n",
      "[nltk_data]    | Downloading package verbnet3 to\n",
      "[nltk_data]    |     /Users/gemmanoguera/nltk_data...\n",
      "[nltk_data]    |   Package verbnet3 is already up-to-date!\n",
      "[nltk_data]    | Downloading package webtext to\n",
      "[nltk_data]    |     /Users/gemmanoguera/nltk_data...\n",
      "[nltk_data]    |   Package webtext is already up-to-date!\n",
      "[nltk_data]    | Downloading package wmt15_eval to\n",
      "[nltk_data]    |     /Users/gemmanoguera/nltk_data...\n",
      "[nltk_data]    |   Package wmt15_eval is already up-to-date!\n",
      "[nltk_data]    | Downloading package word2vec_sample to\n",
      "[nltk_data]    |     /Users/gemmanoguera/nltk_data...\n",
      "[nltk_data]    |   Package word2vec_sample is already up-to-date!\n",
      "[nltk_data]    | Downloading package wordnet to\n",
      "[nltk_data]    |     /Users/gemmanoguera/nltk_data...\n",
      "[nltk_data]    |   Package wordnet is already up-to-date!\n",
      "[nltk_data]    | Downloading package wordnet2021 to\n",
      "[nltk_data]    |     /Users/gemmanoguera/nltk_data...\n",
      "[nltk_data]    |   Package wordnet2021 is already up-to-date!\n",
      "[nltk_data]    | Downloading package wordnet2022 to\n",
      "[nltk_data]    |     /Users/gemmanoguera/nltk_data...\n",
      "[nltk_data]    |   Package wordnet2022 is already up-to-date!\n",
      "[nltk_data]    | Downloading package wordnet31 to\n",
      "[nltk_data]    |     /Users/gemmanoguera/nltk_data...\n",
      "[nltk_data]    |   Package wordnet31 is already up-to-date!\n",
      "[nltk_data]    | Downloading package wordnet_ic to\n",
      "[nltk_data]    |     /Users/gemmanoguera/nltk_data...\n",
      "[nltk_data]    |   Package wordnet_ic is already up-to-date!\n",
      "[nltk_data]    | Downloading package words to\n",
      "[nltk_data]    |     /Users/gemmanoguera/nltk_data...\n",
      "[nltk_data]    |   Package words is already up-to-date!\n",
      "[nltk_data]    | Downloading package ycoe to\n",
      "[nltk_data]    |     /Users/gemmanoguera/nltk_data...\n",
      "[nltk_data]    |   Package ycoe is already up-to-date!\n",
      "[nltk_data]    | \n",
      "[nltk_data]  Done downloading collection all\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('all')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0d952ab",
   "metadata": {},
   "source": [
    "# EXERCICI 1\n",
    "## FREQÜÈNCIA PARAULES\n",
    "### TEXT: ALICE IN WONDERLAND - DOWN RABBIT HOLE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8e942bc9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Alice was beginning to get very tired of sitting by her\n",
      "sister on the bank, and of having nothing to do: once or\n",
      "twice she had peeped into the book her sister was reading,\n",
      "but it had no pictures or conversations in it, ‘and what is\n",
      "the use of a book,’ thought Alice ‘without pictures or\n",
      "conversation?’\n",
      "So she was considering in her own mind (as well as she\n",
      "could, for the hot day made her feel very sleepy and\n",
      "stupid), whether the pleasure of making a daisy-chain\n",
      "would be worth the trouble of getting up and picking the\n",
      "daisies, when suddenly a White Rabbit with pink eyes ran\n",
      "close by her.\n",
      "There was nothing so very remarkable in that; nor did\n",
      "Alice think it so very much out of the way to hear the\n",
      "Rabbit say to itself, ‘Oh dear! Oh dear! I shall be late!’\n",
      "(when she thought it over afterwards, it occurred to her\n",
      "that she ought to have wondered at this, but at the time it\n",
      "all seemed quite natural); but when the Rabbit actually\n",
      "took a watch out of its waistcoat-pocket, and looked at it, and\n",
      "then hurried on, Alice started to her feet, for it flashed\n",
      "across her mind that she had never before seen a rabbit\n",
      "with either a waistcoat-pocket, or a watch to take out of\n",
      "it, and burning with curiosity, she ran across the field after\n",
      "it, and fortunately was just in time to see it pop down a\n",
      "large rabbit-hole under the hedge.\n",
      "In another moment down went Alice after it, never\n",
      "once considering how in the world she was to get out\n",
      "again.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# import nltk -> processament del llenguatge natural\n",
    "\n",
    "# importar llibreries -> tractament de dades\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import string\n",
    "import re\n",
    "\n",
    "# processat i modelat\n",
    "\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer #anàlisi sentiment\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer, PorterStemmer\n",
    "\n",
    "\n",
    "# descarrega text a analitzar\n",
    "\n",
    "awl = open('alice_in_wonderland.txt', 'r')\n",
    "rh = awl.read()\n",
    "\n",
    "print(rh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4c1bc968",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "alice was beginning to get very tired of sitting by her sister on the bank  and of having nothing to do  once or twice she had peeped into the book her sister was reading  but it had no pictures or conversations in it  ‘and what is the use of a book ’ thought alice ‘without pictures or conversation ’ so she was considering in her own mind  as well as she could  for the hot day made her feel very sleepy and stupid   whether the pleasure of making a daisy chain would be worth the trouble of getting up and picking the daisies  when suddenly a white rabbit with pink eyes ran close by her  there was nothing so very remarkable in that  nor did alice think it so very much out of the way to hear the rabbit say to itself  ‘oh dear  oh dear  i shall be late ’  when she thought it over afterwards  it occurred to her that she ought to have wondered at this  but at the time it all seemed quite natural   but when the rabbit actually took a watch out of its waistcoat pocket  and looked at it  and then hurried on  alice started to her feet  for it flashed across her mind that she had never before seen a rabbit with either a waistcoat pocket  or a watch to take out of it  and burning with curiosity  she ran across the field after it  and fortunately was just in time to see it pop down a large rabbit hole under the hedge  in another moment down went alice after it  never once considering how in the world she was to get out again  \n"
     ]
    }
   ],
   "source": [
    "# neteja text\n",
    "\n",
    "# text en minúscules\n",
    "rh_m = rh.lower()\n",
    "\n",
    "\n",
    "# eliminació números\n",
    "rh_nn = re.sub(\"\\d+\", ' ', rh_m)\n",
    " \n",
    "# eliminació espais multiples en blanc\n",
    "rh_e = re.sub(\"\\\\s+\", ' ', rh_nn)\n",
    "\n",
    "\n",
    "# eliminació signes puntuació\n",
    "punt = '[\\\\!\\\\\"\\\\#\\\\$\\\\%\\\\&\\\\\\'\\\\(\\\\)\\\\*\\\\+\\\\,\\\\-\\\\.\\\\/\\\\:\\\\´\\\\;\\\\<\\\\=\\\\>\\\\?\\\\@\\\\[\\\\\\\\\\\\]\\\\^_\\\\`\\\\{\\\\|\\\\}\\\\~]'\n",
    "rh_p = re.sub(punt , ' ', rh_e)\n",
    "print(rh_p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "240ba255",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "alice 5\n",
      "was 6\n",
      "beginning 1\n",
      "to 10\n",
      "get 2\n",
      "very 4\n",
      "tired 1\n",
      "of 8\n",
      "sitting 1\n",
      "by 2\n",
      "her 8\n",
      "sister 2\n",
      "on 2\n",
      "the 14\n",
      "bank 1\n",
      "and 7\n",
      "having 1\n",
      "nothing 2\n",
      "do 1\n",
      "once 2\n",
      "or 4\n",
      "twice 1\n",
      "she 8\n",
      "had 3\n",
      "peeped 1\n",
      "into 1\n",
      "book 2\n",
      "reading 1\n",
      "but 3\n",
      "it 12\n",
      "no 1\n",
      "pictures 2\n",
      "conversations 1\n",
      "in 6\n",
      "‘and 1\n",
      "what 1\n",
      "is 1\n",
      "use 1\n",
      "a 8\n",
      "’ 3\n",
      "thought 2\n",
      "‘without 1\n",
      "conversation 1\n",
      "so 3\n",
      "considering 2\n",
      "own 1\n",
      "mind 2\n",
      "as 2\n",
      "well 1\n",
      "could 1\n",
      "for 2\n",
      "hot 1\n",
      "day 1\n",
      "made 1\n",
      "feel 1\n",
      "sleepy 1\n",
      "stupid 1\n",
      "whether 1\n",
      "pleasure 1\n",
      "making 1\n",
      "daisy 1\n",
      "chain 1\n",
      "would 1\n",
      "be 2\n",
      "worth 1\n",
      "trouble 1\n",
      "getting 1\n",
      "up 1\n",
      "picking 1\n",
      "daisies 1\n",
      "when 3\n",
      "suddenly 1\n",
      "white 1\n",
      "rabbit 5\n",
      "with 3\n",
      "pink 1\n",
      "eyes 1\n",
      "ran 2\n",
      "close 1\n",
      "there 1\n",
      "remarkable 1\n",
      "that 3\n",
      "nor 1\n",
      "did 1\n",
      "think 1\n",
      "much 1\n",
      "out 4\n",
      "way 1\n",
      "hear 1\n",
      "say 1\n",
      "itself 1\n",
      "‘oh 1\n",
      "dear 2\n",
      "oh 1\n",
      "i 1\n",
      "shall 1\n",
      "late 1\n",
      "over 1\n",
      "afterwards 1\n",
      "occurred 1\n",
      "ought 1\n",
      "have 1\n",
      "wondered 1\n",
      "at 3\n",
      "this 1\n",
      "time 2\n",
      "all 1\n",
      "seemed 1\n",
      "quite 1\n",
      "natural 1\n",
      "actually 1\n",
      "took 1\n",
      "watch 2\n",
      "its 1\n",
      "waistcoat 2\n",
      "pocket 2\n",
      "looked 1\n",
      "then 1\n",
      "hurried 1\n",
      "started 1\n",
      "feet 1\n",
      "flashed 1\n",
      "across 2\n",
      "never 2\n",
      "before 1\n",
      "seen 1\n",
      "either 1\n",
      "take 1\n",
      "burning 1\n",
      "curiosity 1\n",
      "field 1\n",
      "after 2\n",
      "fortunately 1\n",
      "just 1\n",
      "see 1\n",
      "pop 1\n",
      "down 2\n",
      "large 1\n",
      "hole 1\n",
      "under 1\n",
      "hedge 1\n",
      "another 1\n",
      "moment 1\n",
      "went 1\n",
      "how 1\n",
      "world 1\n",
      "again 1\n"
     ]
    }
   ],
   "source": [
    "# freqüència de paraules\n",
    "\n",
    "from collections import Counter\n",
    "\n",
    "paraules = rh_p.split()\n",
    "frequencia = Counter(paraules)\n",
    "\n",
    "for paraula, frec in frequencia.items():\n",
    "    print(paraula, frec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9083be49",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# gràfica 10 paraules més freqüents\n",
    "\n",
    "paraula_freq = frequencia.most_common(10)\n",
    "\n",
    "# convertir dos llistes separades per graficar\n",
    "\n",
    "paraules, frequencies = zip(*paraula_freq)\n",
    "\n",
    "plt.bar(paraules, frequencies)\n",
    "plt.title('paraules més frequets')\n",
    "plt.xlabel('paraula')\n",
    "plt.ylabel('freqüència')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fed1bbb",
   "metadata": {},
   "source": [
    "# EXERCICI 2\n",
    "### RETIRADA STOPWORDS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d82703a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['alice', 'beginning', 'get', 'tired', 'sitting', 'sister', 'bank', 'nothing', 'twice', 'peeped', 'book', 'sister', 'reading', 'pictures', 'conversations', '‘', 'use', 'book', '’', 'thought', 'alice', '‘', 'without', 'pictures', 'conversation', '’', 'considering', 'mind', 'well', 'could', 'hot', 'day', 'made', 'feel', 'sleepy', 'stupid', 'whether', 'pleasure', 'making', 'daisy', 'chain', 'would', 'worth', 'trouble', 'getting', 'picking', 'daisies', 'suddenly', 'white', 'rabbit', 'pink', 'eyes', 'ran', 'close', 'nothing', 'remarkable', 'alice', 'think', 'much', 'way', 'hear', 'rabbit', 'say', '‘', 'oh', 'dear', 'oh', 'dear', 'shall', 'late', '’', 'thought', 'afterwards', 'occurred', 'ought', 'wondered', 'time', 'seemed', 'quite', 'natural', 'rabbit', 'actually', 'took', 'watch', 'waistcoat', 'pocket', 'looked', 'hurried', 'alice', 'started', 'feet', 'flashed', 'across', 'mind', 'never', 'seen', 'rabbit', 'either', 'waistcoat', 'pocket', 'watch', 'take', 'burning', 'curiosity', 'ran', 'across', 'field', 'fortunately', 'time', 'see', 'pop', 'large', 'rabbit', 'hole', 'hedge', 'another', 'moment', 'went', 'alice', 'never', 'considering', 'world', 'get']\n"
     ]
    }
   ],
   "source": [
    "# tokenitzar el text \n",
    "tokens = word_tokenize(rh_p.lower())\n",
    "\n",
    "\n",
    "# retirada stopwords (eliminació paraules buides)\n",
    "filtre_tokens = [token for token in tokens if token not in stopwords.words('english')]\n",
    "\n",
    "print(filtre_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "061a1b12",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "alice beginning get tired sitting sister bank nothing twice peeped book sister reading pictures conversations ‘ use book ’ thought alice ‘ without pictures conversation ’ considering mind well could hot day made feel sleepy stupid whether pleasure making daisy chain would worth trouble getting picking daisies suddenly white rabbit pink eyes ran close nothing remarkable alice think much way hear rabbit say ‘ oh dear oh dear shall late ’ thought afterwards occurred ought wondered time seemed quite natural rabbit actually took watch waistcoat pocket looked hurried alice started feet flashed across mind never seen rabbit either waistcoat pocket watch take burning curiosity ran across field fortunately time see pop large rabbit hole hedge another moment went alice never considering world get\n"
     ]
    }
   ],
   "source": [
    "# conversió a string\n",
    "\n",
    "tok = ' '.join(filtre_tokens)\n",
    "print(tok)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4d33c8bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "alice 5\n",
      "beginning 1\n",
      "get 2\n",
      "tired 1\n",
      "sitting 1\n",
      "sister 2\n",
      "bank 1\n",
      "nothing 2\n",
      "twice 1\n",
      "peeped 1\n",
      "book 2\n",
      "reading 1\n",
      "pictures 2\n",
      "conversations 1\n",
      "‘ 3\n",
      "use 1\n",
      "’ 3\n",
      "thought 2\n",
      "without 1\n",
      "conversation 1\n",
      "considering 2\n",
      "mind 2\n",
      "well 1\n",
      "could 1\n",
      "hot 1\n",
      "day 1\n",
      "made 1\n",
      "feel 1\n",
      "sleepy 1\n",
      "stupid 1\n",
      "whether 1\n",
      "pleasure 1\n",
      "making 1\n",
      "daisy 1\n",
      "chain 1\n",
      "would 1\n",
      "worth 1\n",
      "trouble 1\n",
      "getting 1\n",
      "picking 1\n",
      "daisies 1\n",
      "suddenly 1\n",
      "white 1\n",
      "rabbit 5\n",
      "pink 1\n",
      "eyes 1\n",
      "ran 2\n",
      "close 1\n",
      "remarkable 1\n",
      "think 1\n",
      "much 1\n",
      "way 1\n",
      "hear 1\n",
      "say 1\n",
      "oh 2\n",
      "dear 2\n",
      "shall 1\n",
      "late 1\n",
      "afterwards 1\n",
      "occurred 1\n",
      "ought 1\n",
      "wondered 1\n",
      "time 2\n",
      "seemed 1\n",
      "quite 1\n",
      "natural 1\n",
      "actually 1\n",
      "took 1\n",
      "watch 2\n",
      "waistcoat 2\n",
      "pocket 2\n",
      "looked 1\n",
      "hurried 1\n",
      "started 1\n",
      "feet 1\n",
      "flashed 1\n",
      "across 2\n",
      "never 2\n",
      "seen 1\n",
      "either 1\n",
      "take 1\n",
      "burning 1\n",
      "curiosity 1\n",
      "field 1\n",
      "fortunately 1\n",
      "see 1\n",
      "pop 1\n",
      "large 1\n",
      "hole 1\n",
      "hedge 1\n",
      "another 1\n",
      "moment 1\n",
      "went 1\n",
      "world 1\n"
     ]
    }
   ],
   "source": [
    "# freqüència de paraules després de tokanitzar\n",
    "\n",
    "parau = tok.split()\n",
    "fre = Counter(parau)\n",
    "\n",
    "for paraula, frec in fre.items():\n",
    "    print(paraula, frec)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24fc381e",
   "metadata": {},
   "source": [
    "### STEMMING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2efde7e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "large book thought ought alice mind shall without trouble peeped getting remarkable way natural time whether day pocket conversations dear pictures curiosity fortunately made pink pleasure oh get reading hedge picking burning world quite could much stupid well conversation ran daisies pop think moment would suddenly looked feel beginning field never occurred eyes wondered nothing say flashed ’ rabbit see tired seemed use bank another took making ‘ feet seen afterwards hot late white hurried went waistcoat actually watch worth sleepy sitting across considering sister take hear daisy chain close either started hole twice\n"
     ]
    }
   ],
   "source": [
    "# eliminació paraules repetides\n",
    "\n",
    "tokk = tok.split(' ')\n",
    "tok_tok = ' '.join(set(tokk))\n",
    "print(tok_tok)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b8b58fb1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--Word--            --Stem--            \n",
      "large               larg                \n",
      "book                book                \n",
      "thought             thought             \n",
      "ought               ought               \n",
      "alice               alic                \n",
      "mind                mind                \n",
      "shall               shall               \n",
      "without             without             \n",
      "trouble             troubl              \n",
      "peeped              peep                \n",
      "getting             get                 \n",
      "remarkable          remark              \n",
      "way                 way                 \n",
      "natural             natur               \n",
      "time                time                \n",
      "whether             whether             \n",
      "day                 day                 \n",
      "pocket              pocket              \n",
      "conversations       convers             \n",
      "dear                dear                \n",
      "pictures            pictur              \n",
      "curiosity           curios              \n",
      "fortunately         fortun              \n",
      "made                made                \n",
      "pink                pink                \n",
      "pleasure            pleasur             \n",
      "oh                  oh                  \n",
      "get                 get                 \n",
      "reading             read                \n",
      "hedge               hedg                \n",
      "picking             pick                \n",
      "burning             burn                \n",
      "world               world               \n",
      "quite               quit                \n",
      "could               could               \n",
      "much                much                \n",
      "stupid              stupid              \n",
      "well                well                \n",
      "conversation        convers             \n",
      "ran                 ran                 \n",
      "daisies             daisi               \n",
      "pop                 pop                 \n",
      "think               think               \n",
      "moment              moment              \n",
      "would               would               \n",
      "suddenly            suddenli            \n",
      "looked              look                \n",
      "feel                feel                \n",
      "beginning           begin               \n",
      "field               field               \n",
      "never               never               \n",
      "occurred            occur               \n",
      "eyes                eye                 \n",
      "wondered            wonder              \n",
      "nothing             noth                \n",
      "say                 say                 \n",
      "flashed             flash               \n",
      "’                   ’                   \n",
      "rabbit              rabbit              \n",
      "see                 see                 \n",
      "tired               tire                \n",
      "seemed              seem                \n",
      "use                 use                 \n",
      "bank                bank                \n",
      "another             anoth               \n",
      "took                took                \n",
      "making              make                \n",
      "‘                   ‘                   \n",
      "feet                feet                \n",
      "seen                seen                \n",
      "afterwards          afterward           \n",
      "hot                 hot                 \n",
      "late                late                \n",
      "white               white               \n",
      "hurried             hurri               \n",
      "went                went                \n",
      "waistcoat           waistcoat           \n",
      "actually            actual              \n",
      "watch               watch               \n",
      "worth               worth               \n",
      "sleepy              sleepi              \n",
      "sitting             sit                 \n",
      "across              across              \n",
      "considering         consid              \n",
      "sister              sister              \n",
      "take                take                \n",
      "hear                hear                \n",
      "daisy               daisi               \n",
      "chain               chain               \n",
      "close               close               \n",
      "either              either              \n",
      "started             start               \n",
      "hole                hole                \n",
      "twice               twice               \n"
     ]
    }
   ],
   "source": [
    "# Initialize Python porter stemmer\n",
    "ps = PorterStemmer()\n",
    "\n",
    "# stemming\n",
    "print(\"{0:20}{1:20}\".format(\"--Word--\",\"--Stem--\"))\n",
    "for word in word_tok:\n",
    "    print (\"{0:20}{1:20}\".format(word, ps.stem(word)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63434fe6",
   "metadata": {},
   "source": [
    "# EXERCICI 3\n",
    "### ANÀLISI DE SENTIMENT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "07b14825",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting textblob\n",
      "  Downloading textblob-0.17.1-py2.py3-none-any.whl (636 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m636.8/636.8 kB\u001b[0m \u001b[31m1.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: nltk>=3.1 in ./opt/anaconda3/lib/python3.9/site-packages (from textblob) (3.7)\n",
      "Requirement already satisfied: regex>=2021.8.3 in ./opt/anaconda3/lib/python3.9/site-packages (from nltk>=3.1->textblob) (2022.3.15)\n",
      "Requirement already satisfied: joblib in ./opt/anaconda3/lib/python3.9/site-packages (from nltk>=3.1->textblob) (1.1.0)\n",
      "Requirement already satisfied: click in ./opt/anaconda3/lib/python3.9/site-packages (from nltk>=3.1->textblob) (8.0.4)\n",
      "Requirement already satisfied: tqdm in ./opt/anaconda3/lib/python3.9/site-packages (from nltk>=3.1->textblob) (4.64.0)\n",
      "Installing collected packages: textblob\n",
      "Successfully installed textblob-0.17.1\n"
     ]
    }
   ],
   "source": [
    "! pip install -U textblob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "227f989b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package brown to\n",
      "[nltk_data]     /Users/gemmanoguera/nltk_data...\n",
      "[nltk_data]   Package brown is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /Users/gemmanoguera/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /Users/gemmanoguera/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     /Users/gemmanoguera/nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n",
      "[nltk_data] Downloading package conll2000 to\n",
      "[nltk_data]     /Users/gemmanoguera/nltk_data...\n",
      "[nltk_data]   Package conll2000 is already up-to-date!\n",
      "[nltk_data] Downloading package movie_reviews to\n",
      "[nltk_data]     /Users/gemmanoguera/nltk_data...\n",
      "[nltk_data]   Package movie_reviews is already up-to-date!\n",
      "Finished.\n"
     ]
    }
   ],
   "source": [
    "! python -m textblob.download_corpora"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "1b285291",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.015306122448979585\n"
     ]
    }
   ],
   "source": [
    "from textblob import TextBlob\n",
    "\n",
    "text = tok_tok\n",
    "\n",
    "blob = TextBlob(text)\n",
    "\n",
    "# atribut etiqueta clau-valor\n",
    "blob.tags\n",
    "\n",
    "# obtenció llista paraules substantives\n",
    "blob.noun_phrases   \n",
    "\n",
    "for sentence in blob.sentences:\n",
    "    print(sentence.sentiment.polarity)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4822be1a",
   "metadata": {},
   "source": [
    "### puntuació de polaritat és un valor flotant dins el rango [-1.0, 1.0]\n",
    "### subjectividad valor dins intervalo [0,0, 1,0]\n",
    "### 0,0 -> molt objectiu\n",
    "### 1,0 -> molt subjectiu\n",
    "\n",
    "## text objectiu"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
